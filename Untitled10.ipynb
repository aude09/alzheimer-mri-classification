{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce1f19dc-bf5a-417f-9303-124d0415b66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: [1.7681159973144531, 0.8840579986572266, 0.7672955989837646]\n",
      "Epoch 1/50, Loss: 1.1190\n",
      "Epoch 2/50, Loss: 1.0986\n",
      "Epoch 3/50, Loss: 1.0971\n",
      "Epoch 4/50, Loss: 1.0949\n",
      "Epoch 5/50, Loss: 1.0864\n",
      "Epoch 6/50, Loss: 1.0851\n",
      "Epoch 7/50, Loss: 1.0625\n",
      "Epoch 8/50, Loss: 1.0342\n",
      "Epoch 9/50, Loss: 0.9789\n",
      "Epoch 10/50, Loss: 0.8973\n",
      "Epoch 11/50, Loss: 0.8796\n",
      "Epoch 12/50, Loss: 0.8595\n",
      "Epoch 13/50, Loss: 0.7280\n",
      "Epoch 14/50, Loss: 0.6671\n",
      "Epoch 15/50, Loss: 0.6218\n",
      "Epoch 16/50, Loss: 0.5265\n",
      "Epoch 17/50, Loss: 0.3945\n",
      "Epoch 18/50, Loss: 0.2973\n",
      "Epoch 19/50, Loss: 0.2204\n",
      "Epoch 20/50, Loss: 0.1997\n",
      "Epoch 21/50, Loss: 0.1372\n",
      "Epoch 22/50, Loss: 0.1217\n",
      "Epoch 23/50, Loss: 0.1403\n",
      "Epoch 24/50, Loss: 0.1144\n",
      "Epoch 25/50, Loss: 0.0750\n",
      "Epoch 26/50, Loss: 0.0382\n",
      "Epoch 27/50, Loss: 0.0203\n",
      "Epoch 28/50, Loss: 0.0143\n",
      "Epoch 29/50, Loss: 0.0108\n",
      "Epoch 30/50, Loss: 0.0081\n",
      "Epoch 31/50, Loss: 0.0060\n",
      "Epoch 32/50, Loss: 0.0073\n",
      "Epoch 33/50, Loss: 0.0033\n",
      "Epoch 34/50, Loss: 0.0040\n",
      "Epoch 35/50, Loss: 0.0024\n",
      "Epoch 36/50, Loss: 0.0045\n",
      "Epoch 37/50, Loss: 0.0026\n",
      "Epoch 38/50, Loss: 0.0021\n",
      "Epoch 39/50, Loss: 0.0025\n",
      "Epoch 40/50, Loss: 0.0012\n",
      "Epoch 41/50, Loss: 0.0032\n",
      "Epoch 42/50, Loss: 0.0018\n",
      "Epoch 43/50, Loss: 0.0033\n",
      "Epoch 44/50, Loss: 0.0027\n",
      "Epoch 45/50, Loss: 0.0019\n",
      "Epoch 46/50, Loss: 0.0044\n",
      "Epoch 47/50, Loss: 0.0025\n",
      "Epoch 48/50, Loss: 0.0012\n",
      "Epoch 49/50, Loss: 0.0009\n",
      "Epoch 50/50, Loss: 0.0011\n",
      "Accuracy: 69.35%\n"
     ]
    }
   ],
   "source": [
    "# === Étape 1 : Imports ===\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# === Étape 2 : Chemins ===\n",
    "data_dir = \"C:/Users/merveille/Downloads/ADNI_annuel/ADNI\"\n",
    "metadata_csv = \"C:/Users/merveille/Downloads/ADNI1_Annual_2_Yr_3T_4_11_2025.csv\"\n",
    "\n",
    "# === Étape 3 : Charger les métadonnées ===\n",
    "df = pd.read_csv(metadata_csv)\n",
    "df = df.dropna(subset=[\"Image Data ID\", \"Group\"])\n",
    "\n",
    "# === Étape 4 : Associer les fichiers NIfTI aux ImageUID ===\n",
    "def find_nifti_file(image_uid):\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".nii\") or file.endswith(\".nii.gz\"):\n",
    "                if str(image_uid) in file:\n",
    "                    return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "df[\"nifti_path\"] = df[\"Image Data ID\"].apply(find_nifti_file)\n",
    "df = df.dropna(subset=[\"nifti_path\"])\n",
    "\n",
    "# === Étape 5 : Préparer les labels ===\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"Group\"])  # CN=0, MCI=1, AD=2\n",
    "\n",
    "# === Étape 6 : Dataset PyTorch ===\n",
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        self.target_shape = (64, 64, 64)  # redimensionnement uniforme\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx][\"nifti_path\"]\n",
    "        label = self.df.iloc[idx][\"label\"]\n",
    "        img = nib.load(path).get_fdata()\n",
    "        img = self._resize_image(img)\n",
    "        img = (img - np.mean(img)) / np.std(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "    def _resize_image(self, image):\n",
    "        from scipy.ndimage import zoom\n",
    "        factors = [t / s for t, s in zip(self.target_shape, image.shape)]\n",
    "        return zoom(image, factors, order=1)\n",
    "\n",
    "# === Étape 7 : Séparation train/test ===\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n",
    "train_dataset = AlzheimerDataset(df_train)\n",
    "test_dataset = AlzheimerDataset(df_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10)\n",
    "\n",
    "# === Étape 8 : Modèle CNN 3D ===\n",
    "class CNN3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "        self.conv4 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.AdaptiveMaxPool3d((4, 4, 4))\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4 * 4, 256)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# === Étape 9 : Entraînement ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN3D().to(device)\n",
    "\n",
    "#  Calcul automatique des poids de classe\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "class_counts = torch.tensor([(torch.tensor(train_labels) == i).sum().item() for i in range(3)], dtype=torch.float)\n",
    "total_samples = class_counts.sum()\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "print(f\"Class weights: {class_weights.tolist()}\")\n",
    "\n",
    "# CrossEntropyLoss pondérée\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# === Étape 10 : Évaluation ===\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6218ca5e-024d-49dc-a68f-5ee5d41b259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CN       0.33      0.08      0.13        12\n",
      "         MCI       0.48      0.65      0.56        23\n",
      "          AD       0.68      0.70      0.69        27\n",
      "\n",
      "    accuracy                           0.56        62\n",
      "   macro avg       0.50      0.48      0.46        62\n",
      "weighted avg       0.54      0.56      0.53        62\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  9  2]\n",
      " [ 1 15  7]\n",
      " [ 1  7 19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Après l'évaluation de ton modèle :\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Rapport détaillé\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"CN\", \"MCI\", \"AD\"]))\n",
    "\n",
    "# Matrice de confusion\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e175be-a53c-4749-9862-36dca5e3d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(nifti_path, model, le, target_shape=(64, 64, 64)):\n",
    "    import nibabel as nib\n",
    "    from scipy.ndimage import zoom\n",
    "\n",
    "    # Charger et prétraiter l'image\n",
    "    img = nib.load(nifti_path).get_fdata()\n",
    "    factors = [t / s for t, s in zip(target_shape, img.shape)]\n",
    "    img = zoom(img, factors, order=1)\n",
    "    std = np.std(img)\n",
    "    img = (img - np.mean(img)) / std if std > 0 else img\n",
    "    img = np.expand_dims(img, axis=0)  # pour channel\n",
    "    img = np.expand_dims(img, axis=0)  # pour batch\n",
    "\n",
    "    # Convertir en tenseur\n",
    "    input_tensor = torch.tensor(img, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Prédiction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        predicted_label = le.inverse_transform([predicted.cpu().item()])[0]\n",
    "\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34ee7ff3-39e0-448d-89bd-a79b39e04560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction : AD\n"
     ]
    }
   ],
   "source": [
    "path_to_image = \"C:/Users/merveille/Downloads/test2/ADNI/130_S_0956/MPR____N3__Scaled/2007-11-01_09_21_36.0/I82700/ADNI_130_S_0956_MR_MPR____N3__Scaled_Br_20071119103328096_S42138_I82700.nii\"\n",
    "prediction = predict_image(path_to_image, model, le)\n",
    "print(\"Prédiction :\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69432734-f4a4-4655-956a-2e95d9cfd6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dimensions de l'image IRM : (256, 256, 170)\n"
     ]
    }
   ],
   "source": [
    "path_to_image  = \"C:/Users/merveille/Downloads/test2/ADNI/130_S_0956/MPR____N3__Scaled/2007-11-01_09_21_36.0/I82700/ADNI_130_S_0956_MR_MPR____N3__Scaled_Br_20071119103328096_S42138_I82700.nii\"\n",
    "img = nib.load(path_to_image )\n",
    "img_data = img.get_fdata()\n",
    "print(f\"[INFO] Dimensions de l'image IRM : {img_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ed6b97d-9632-4944-a8d5-b674ab97071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dicom2nifti in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from dicom2nifti) (5.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from dicom2nifti) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from dicom2nifti) (1.13.1)\n",
      "Requirement already satisfied: pydicom>=2.2.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from dicom2nifti) (3.0.1)\n",
      "Requirement already satisfied: python-gdcm in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from dicom2nifti) (3.0.24.1)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nibabel->dicom2nifti) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nibabel->dicom2nifti) (4.11.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (5.3.2)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nibabel) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nibabel) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nibabel) (4.11.0)\n",
      "Requirement already satisfied: nilearn in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (0.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (1.4.2)\n",
      "Requirement already satisfied: lxml in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (5.2.1)\n",
      "Requirement already satisfied: nibabel>=5.2.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (5.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (24.1)\n",
      "Requirement already satisfied: pandas>=2.2.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (2.32.3)\n",
      "Requirement already satisfied: scikit-learn>=1.4.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nilearn) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from nibabel>=5.2.0->nilearn) (4.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from pandas>=2.2.0->nilearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from pandas>=2.2.0->nilearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from pandas>=2.2.0->nilearn) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from requests>=2.25.0->nilearn) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from requests>=2.25.0->nilearn) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from requests>=2.25.0->nilearn) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from requests>=2.25.0->nilearn) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from scikit-learn>=1.4.0->nilearn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\merveille\\downloads\\anaconda1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.2.0->nilearn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dicom2nifti\n",
    "!pip install nibabel\n",
    "!pip install nilearn\n",
    "import dicom2nifti\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "import scipy.ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0b782-80e0-4e54-873b-abc8086ed670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
